import torch
import numpy as np
import pandas as pd
from PIL import Image
from torchvision import transforms
from pathlib import Path
from tqdm import tqdm
import os
import time

# Optimizaci√≥n CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")

# Cargar modelo
print("Cargando DINOv2...")
model = torch.hub.load("facebookresearch/dinov2", "dinov2_vitg14")
model = model.to(device)
model.eval()

# Transform
transform = transforms.Compose(
    [
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)


def load_images_from_folders(base_path):
    """Carga rutas desde carpetas de categor√≠as Alto, Medio y Bajo"""
    base_path = Path(base_path)
    image_paths = []
    labels = []
    categories = []

    # Definir las categor√≠as en orden espec√≠fico
    category_names = ["Alto", "Medio", "Bajo"]

    print(f"\nüìÅ Categor√≠as a procesar:")
    for idx, cat_name in enumerate(category_names):
        cat_folder = base_path / cat_name

        if not cat_folder.exists():
            print(f"   ‚ö†Ô∏è  {cat_name} - Carpeta no encontrada, saltando...")
            continue

        images = list(cat_folder.glob("*.jpg")) + list(cat_folder.glob("*.png"))

        print(f"   {idx}: {cat_name} - {len(images)} im√°genes")

        for img_path in images:
            image_paths.append(str(img_path))
            labels.append(idx)
            categories.append(cat_name)

    print(f"\n‚úÖ Total: {len(image_paths)} im√°genes")
    return image_paths, labels, categories


def extract_features(image_paths, batch_size=16):
    """Extrae features con contador detallado"""
    n = len(image_paths)
    features = np.zeros((n, 1536), dtype=np.float32)

    start_time = time.time()
    errors = 0

    # Barra de progreso con detalles
    pbar = tqdm(
        total=n,
        desc="Extrayendo features",
        unit="img",
        bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
    )

    with torch.no_grad():
        for i in range(0, n, batch_size):
            batch_start = time.time()
            batch_paths = image_paths[i : i + batch_size]
            batch = []

            for path in batch_paths:
                try:
                    img = Image.open(path).convert("RGB")
                    batch.append(transform(img))
                except Exception as e:
                    errors += 1
                    batch.append(torch.zeros(3, 224, 224))

            batch_tensor = torch.stack(batch).to(device)
            feat = model(batch_tensor).cpu().numpy()
            features[i : i + len(batch)] = feat

            # Actualizar progreso
            pbar.update(len(batch))

            # Calcular estad√≠sticas cada 100 im√°genes
            if (i + batch_size) % 100 == 0 or (i + batch_size) >= n:
                elapsed = time.time() - start_time
                processed = min(i + batch_size, n)
                imgs_per_sec = processed / elapsed
                remaining_imgs = n - processed
                eta_seconds = remaining_imgs / imgs_per_sec if imgs_per_sec > 0 else 0

                # Actualizar descripci√≥n
                pbar.set_postfix(
                    {
                        "img/s": f"{imgs_per_sec:.1f}",
                        "ETA": f"{eta_seconds/60:.1f}min",
                        "errors": errors,
                    }
                )

    pbar.close()

    # Resumen final
    total_time = time.time() - start_time
    print(f"\n{'='*60}")
    print(f"‚úÖ Extracci√≥n completada!")
    print(f"   Tiempo total: {total_time/60:.1f} minutos ({total_time:.1f} segundos)")
    print(f"   Im√°genes procesadas: {n}")
    print(f"   Velocidad promedio: {n/total_time:.2f} img/s")
    print(f"   Errores: {errors}")
    print(f"{'='*60}\n")

    return features


# ============ EJECUTAR ============

if __name__ == "__main__":
    print(f"\n{'='*60}")
    print("üèôÔ∏è  EXTRACCI√ìN DE FEATURES - NIVEL SOCIOECON√ìMICO")
    print(f"{'='*60}\n")

    # Cargar datos desde final_images (Alto, Medio, Bajo)
    base_path = "./images"
    image_paths, labels, categories = load_images_from_folders(base_path)

    # Estimaci√≥n de tiempo
    estimated_time = len(image_paths) * 0.5 / 60
    print(f"\n‚è±Ô∏è  Tiempo estimado: ~{estimated_time:.1f} minutos")
    print(f"‚è≥ Iniciando extracci√≥n...\n")

    # Extraer features
    X = extract_features(image_paths, batch_size=16)

    # Crear DataFrame
    df = pd.DataFrame(
        {"image_path": image_paths, "label": labels, "category": categories}
    )

    # Guardar
    print("üíæ Guardando archivos...")
    np.save("X_features.npy", X)
    df.to_csv("y_labels.csv", index=False)

    print(f"\n{'='*60}")
    print("üìä ARCHIVOS GENERADOS:")
    print(f"{'='*60}")
    print(f"   ‚úì X_features.npy - Shape: {X.shape}")
    print(f"   ‚úì y_labels.csv - {len(df)} registros")
    print(f"\nüìà Distribuci√≥n de categor√≠as:")
    print(df["category"].value_counts().to_string())
    print(f"{'='*60}\n")
